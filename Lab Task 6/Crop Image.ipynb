{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fab33f37-3bd6-4c58-8ee9-248d56b91476",
   "metadata": {},
   "source": [
    "# Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58cb19e7-e3b0-4833-ae79-474739132205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef558a2-969b-460d-8768-978b47bfca10",
   "metadata": {},
   "source": [
    "# Load the image and show it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55541ee5-b962-4adc-ab0a-188369876698",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"girl.jfif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c96fe47c-a2e0-4e54-916a-93f3c5f798ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Original\", image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8676af71-82f0-4ad0-95a3-ee833a9b7cf2",
   "metadata": {},
   "source": [
    "# cropping an image is accomplished using simple NumPy array slices --\n",
    "# let's crop the face from the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4a20f98-2759-4c12-a51b-062c04ae0db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "face = image[85:250, 85:220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f66bdad8-3d92-4d2b-8896-fcdece3b2de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Face\", face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbb253c3-a1c7-4b9d-9224-a137e64414bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ea5702-b88d-4f29-b7f6-a7e36b935d92",
   "metadata": {},
   "source": [
    "# ...and now let's crop the entire body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c754d6e4-c05e-4b45-b935-770b91b8f4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = image[90:450, 0:290]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "700edd94-3d74-463e-bb6f-5ef7a50314e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Body\", body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c01eba3b-b93f-49b3-9d74-1dc4058d3e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Hamna Env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
